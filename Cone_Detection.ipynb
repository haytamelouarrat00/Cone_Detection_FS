{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyPCeHhGObjnTVI/r23RedJb",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/haytamelouarrat00/Cone_Detection_FS/blob/master/Cone_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1M0sEL1P_6LB",
    "outputId": "91a04d58-69df-4d8e-ef03-36d8751dbdd2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.49-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
      "Downloading roboflow-1.1.49-py3-none-any.whl (80 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m80.9/80.9 kB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.8/66.8 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: filetype, python-dotenv, idna, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 roboflow-1.1.49\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading Dataset Version Zip in FSAI-11/03/2024-1 to yolov11:: 100%|██████████| 995191/995191 [00:18<00:00, 52890.85it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to FSAI-11/03/2024-1 in yolov11:: 100%|██████████| 47504/47504 [00:07<00:00, 6517.96it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"J09U3OiEmcboSrbUKAgf\")\n",
    "project = rf.workspace(\"fsbdriverless-xi0fv\").project(\"fsai-11-03-2024\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov11\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install ultralytics"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Configuration\n",
    "DATASET_PATH = '/content/FSAI-11/03/2024-1'\n",
    "MODEL_PATH = 'yolo11s.pt'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 640\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Training\n",
    "results = model.train(\n",
    "    data=os.path.join(DATASET_PATH, 'data.yaml'),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=8,\n",
    "    device=0,\n",
    "    plots=True,\n",
    "    project='runs/detect',\n",
    "    name='custom_training',\n",
    "    resume=False,\n",
    "\n",
    "    # Advanced hyperparameters\n",
    "    lr0=0.01,\n",
    "    lrf=0.1,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    close_mosaic=10\n",
    ")\n",
    "\n",
    "# Validation\n",
    "validation_results = model.val()\n",
    "\n",
    "# Export model\n",
    "model.export(format='onnx')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "onnx_model_path = \"runs/detect/custom_training/weights/best.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, img_size=640):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((img_size, img_size))\n",
    "    img_array = np.array(image).astype('float32') / 255.0\n",
    "    img_array = img_array.transpose(2, 0, 1)  # HWC to CHW\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "\n",
    "image_path = \"test1.png\"\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "outputs = ort_session.run(None, {ort_session.get_inputs()[0].name: input_data})\n",
    "print(outputs)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def run_inference(model_path, image_path, conf_thresh=0.25):\n",
    "    \"\"\"\"\"\"\n",
    "    Run YOLO inference on a single image\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to trained YOLO model (.pt file)\n",
    "        image_path: Path to test image\n",
    "        conf_thresh: Confidence threshold for detections\n",
    "    \"\"\"\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    results = model(image_path, conf=conf_thresh)[0]\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot results\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        conf = box.conf[0]\n",
    "        cls = int(box.cls[0])\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        label = f'{results.names[cls]} {conf:.2f}'\n",
    "        cv2.putText(image, label, (x1, y1 - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    output_path = 'result.jpg'\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "\n",
    "    # Print detections\n",
    "    print(\"\\nDetections:\")\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        print(f\"Class: {results.names[cls]}, Confidence: {conf:.2f}\")\n",
    "\n",
    "model_path = \"runs/detect/custom_training/weights/best.pt\"\n",
    "image_path = \"test1.png\"\n",
    "\n",
    "run_inference(model_path, image_path)\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def process_video(model_path, video_path, output_path=None, conf_thresh=0.25):\n",
    "    \"\"\"\n",
    "    Process video with YOLO model\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to trained YOLO model (.pt file)\n",
    "        video_path: Path to input video\n",
    "        output_path: Path for output video (optional)\n",
    "        conf_thresh: Confidence threshold for detections\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if output_path is None:\n",
    "        output_path = str(Path(video_path).with_name(f\"{Path(video_path).stem}_detected.mp4\"))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path,\n",
    "                         cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                         fps,\n",
    "                         (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "\n",
    "        results = model(frame, conf=conf_thresh)[0]\n",
    "\n",
    "        # Draw boxes and labels\n",
    "        annotated_frame = results.plot()\n",
    "\n",
    "        # Add processing info\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps_current = frame_count / elapsed_time\n",
    "        cv2.putText(annotated_frame, f'FPS: {fps_current:.1f}',\n",
    "                   (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "        out.write(annotated_frame)\n",
    "        if frame_count % 30 == 0:  # Update every 30 frames\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_count}/{total_frames} frames)\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"\\nProcessing complete! Output saved to: {output_path}\")\n",
    "    print(f\"Average FPS: {frame_count / elapsed_time:.1f}\")\n",
    "\n",
    "def process_webcam(model_path, conf_thresh=0.25):\n",
    "    \"\"\"\n",
    "    Real-time webcam detection\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to trained YOLO model (.pt file)\n",
    "        conf_thresh: Confidence threshold for detections\n",
    "    \"\"\"\n",
    "    \n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, conf=conf_thresh)[0]\n",
    "        annotated_frame = results.plot()\n",
    "        cv2.imshow('YOLO Detection', annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"runs/detect/custom_training/weights/best.pt\"\n",
    "\n",
    "    # For video file:\n",
    "    video_path = \"testvid.mp4\"\n",
    "    process_video(model_path, video_path)\n",
    "\n",
    "    # For webcam:\n",
    "    # process_webcam(model_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fine-tuning"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('res/weights/best.pt')\n",
    "\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# Run predictions\n",
    "results = model.predict(\n",
    "    source='testvid3.mp4',\n",
    "    conf=confidence_threshold,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    imgsz=640\n",
    ")\n",
    "\n",
    "# Evaluate results (if available metrics are provided)\n",
    "print(results)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
